import os
import glob
import numpy as np
import pandas as pd
import seaborn as snZ
from PIL import Image
from collections import Counter
import matplotlib.pyplot as plt

def importing_data(path):
    sample = []
    for filename in glob.glob(path):
        img = Image.open(filename,'r')
        IMG = np.array(img)
        sample.append(IMG)
    return sample

path1 = 'C:\\Users\\hp\\OneDrive\\Desktop\\MCA FINAL\\Alzheimer_s Dataset\\train\\NonDemented\\*.jpg' 
path2 = 'C:\\Users\\hp\\OneDrive\\Desktop\\MCA FINAL\\Alzheimer_s Dataset\\train\\VeryMildDemented\\*.jpg'
path3 = 'C:\\Users\hp\\OneDrive\\Desktop\\MCA FINAL\\Alzheimer_s Dataset\\train\\MildDemented\\*.jpg'
path4 = 'C:\\Users\\hp\\OneDrive\\Desktop\\MCA FINAL\\Alzheimer_s Dataset\\train\\ModerateDemented\\*.jpg'

path5 = 'C:\\Users\\hp\\OneDrive\\Desktop\\MCA FINAL\\Alzheimer_s Dataset\\test\\NonDemented\\*.jpg' 
path6 = 'C:\\Users\\hp\\OneDrive\\Desktop\\MCA FINAL\\Alzheimer_s Dataset\\test\\VeryMildDemented\\*.jpg'
path7 = 'C:\\Users\\hp\OneDrive\\Desktop\\MCA FINAL\\Alzheimer_s Dataset\\test\\MildDemented\\*.jpg'
path8 = 'C:\\Users\\hp\\OneDrive\\Desktop\\MCA FINAL\\Alzheimer_s Dataset\\test\\ModerateDemented\\*.jpg'



train_ND = importing_data(path1)
train_VMD = importing_data(path2)
train_MID = importing_data(path3)
train_MOD = importing_data(path4)

test_ND = importing_data(path5)
test_VMD = importing_data(path6)
test_MID = importing_data(path7)
test_MOD = importing_data(path8)



img1 = Image.open('C:\\Users\\hp\\OneDrive\\Desktop\\MCA FINAL\\Alzheimer_s Dataset\\train\\NonDemented\\nonDem0.jpg')
img2 = Image.open('C:\\Users\\hp\\OneDrive\\Desktop\\MCA FINAL\\Alzheimer_s Dataset\\train\\VeryMildDemented\\verymildDem972.jpg')
img3 = Image.open('C:\\Users\hp\\OneDrive\\Desktop\\MCA FINAL\\Alzheimer_s Dataset\\train\\MildDemented\\mildDem0.jpg')
img4 = Image.open('C:\\Users\\hp\\OneDrive\\Desktop\\MCA FINAL\\Alzheimer_s Dataset\\train\\ModerateDemented\\moderateDem0.jpg')


fig, (ax1, ax2, ax3, ax4) = plt.subplots(1,4, figsize= (10,10))

ax1.imshow(img1, cmap ="binary_r")
ax1.set_title('Non Demented')
ax2.imshow(img2, cmap ="binary_r")
ax2.set_title('VeryMild Demented')
ax3.imshow(img3, cmap ="binary_r")
ax3.set_title('Mild Demented')
ax4.imshow(img4, cmap ="binary_r")
ax4.set_title('Moderate Demented')
plt.show()

df_train_ND = pd.DataFrame({'image':train_ND, 'label': 'ND'})
df_train_VMD = pd.DataFrame({'image':train_VMD, 'label': 'VMD'})
df_train_MID = pd.DataFrame({'image':train_MID, 'label': 'MID'})
df_train_MOD = pd.DataFrame({'image':train_MOD, 'label': 'MOD'})

df_test_ND = pd.DataFrame({'image':test_ND, 'label': 'ND'})
df_test_VMD = pd.DataFrame({'image':test_VMD, 'label': 'VMD'})
df_test_MID = pd.DataFrame({'image':test_MID, 'label': 'MID'})
df_test_MOD = pd.DataFrame({'image':test_MOD, 'label': 'MOD'})

final_data = [df_train_ND, df_train_VMD, df_train_MID, df_train_MOD,df_test_ND, df_test_VMD, df_test_MID, df_test_MOD]
final_data = pd.concat(final_data)

train_data = final_data['image']
labels = final_data['label']

#%% LOOKING AT THE AMOUNT OF ITEMS PER CLASS 

Counter(np.array(labels))

#%% DATA NORMALIZATION

from sklearn.preprocessing import MinMaxScaler

def normalization(array):
    
    train_norm = []
    transformer = MinMaxScaler()
    
    for value in array:
        value = transformer.fit_transform(value)
        train_norm.append(value)
    
    return train_norm

train_norm = normalization(train_data)

from sklearn.preprocessing import LabelBinarizer

onehot = LabelBinarizer()
labels = onehot.fit_transform(labels)
print(labels)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(train_norm, labels,
                                                  test_size = 0.2,
                                                  stratify = labels,
                                                  shuffle = True,
                                                  random_state = 42)

print('length X_train:', len(X_train))
print('length X_test:',  len(X_test))
print('length y_train:', len(y_train))
print('length y_test:', len(y_test))

X_train = np.array(X_train).reshape(5120,208,176,1)
X_test = np.array(X_test).reshape(1280,208,176,1)

from sklearn.utils.class_weight import compute_class_weight

y_integers = np.argmax(y_train, axis=1)
class_labels = np.unique(y_integers)
class_weights = compute_class_weight(class_weight="balanced",classes=class_labels, y=y_integers)
d_class_weights = dict(zip(class_labels, class_weights))
print(d_class_weights)

from keras.models import Sequential
from keras.layers import Dense, BatchNormalization, Dropout, Conv2D , MaxPooling2D, Flatten
from keras.callbacks import EarlyStopping,ModelCheckpoint
from keras.optimizers import RMSprop
import tensorflow as tf

# Replace the deprecated function with the recommended one
from tensorflow.compat.v1.losses import sparse_softmax_cross_entropy

# Your code continues...


import tensorflow as tf
from keras.metrics import AUC
from keras.models import Sequential
from keras.layers import Dense, BatchNormalization, Dropout, Conv2D , MaxPooling2D, Flatten
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras.optimizers import RMSprop
import warnings

def build_model():
    '''Sequential Model creation'''
    Cnn = Sequential()
    
    Cnn.add(Conv2D(64,(5,5), activation='relu', padding='same', strides=(2,2), input_shape=[208,176,1]))
    Cnn.add(MaxPooling2D(2))
    Cnn.add(Conv2D(128,(5,5), activation='relu', padding='same', strides=(2,2)))
    Cnn.add(Conv2D(128,(5,5), activation='relu', padding='same', strides=(2,2)))
    Cnn.add(Conv2D(256,(5,5), activation='relu', padding='same', strides=(2,2)))
    Cnn.add(MaxPooling2D(2))
    Cnn.add(Flatten())
    Cnn.add(Dense(64, activation='relu'))
    Cnn.add(Dropout(0.4))
    Cnn.add(Dense(32, activation='relu'))
    Cnn.add(Dropout(0.4))
    Cnn.add(Dense(4, activation='softmax'))
    
    return Cnn

# Suppressing TensorFlow deprecation warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)

keras_model = build_model()
keras_model.summary()


def Model_fit(name):
    
    keras_model = None
    
    keras_model = build_model()
    
    '''Compiling the model'''
    
    keras_model.compile(optimizer = RMSprop(learning_rate = 1e-4),
                        loss='categorical_crossentropy',
                        metrics =['acc', 'AUC'])
    
    es = EarlyStopping(monitor='val_loss', mode='min', patience=10 ,
                   restore_best_weights=True, verbose=1)
    
    checkpoint_cb = ModelCheckpoint("AD_Stages_model.h5", save_best_only=True)
    
    history = keras_model.fit(X_train, y_train, validation_split = 0.1,
                    epochs= 100, batch_size = 10, class_weight = d_class_weights ,
                    callbacks=[es, checkpoint_cb])
    
    keras_model.save('AD_Stages_model'+str(name)+'.h5') 
    
    return history

def CrossVal(n_fold):
    cv_results = []
    for i in range(n_fold):
        print("Training on Fold: ", i+1)
        cv_results.append(Model_fit(i))
    return cv_results

cv_results = CrossVal(3)

fold1 = cv_results[0]
fold2 = cv_results[1] 
fold3 = cv_results[2]

#%% CHEKING THE CROSS VALIDATION METRICS

print('Val_Acc Folder 1: ', max(fold1.history['val_acc']))
print('Val_Acc Folder 2: ', max(fold2.history['val_acc']))
print('Val_Acc Folder 3: ', max(fold3.history['val_acc']))
print('--------------------------------')
print('Val_Auc Folder 1: ', max(fold1.history['val_auc']))
print('Val_Auc Folder 2: ', max(fold2.history['val_auc']))
print('Val_Auc Folder 3: ', max(fold3.history['val_auc']))

#%% PLOTTING RESULTS (Train vs Validation FOLDER 1)

def Train_Val_Plot(acc,val_acc,loss,val_loss):
    
    fig, (ax1, ax2) = plt.subplots(1,2, figsize= (20,15))
    fig.suptitle(" MODEL'S METRICS VISUALIZATION ")

    ax1.plot(range(1, len(acc) + 1), acc)
    ax1.plot(range(1, len(val_acc) + 1), val_acc)
    ax1.set_title('History of Accuracy')
    ax1.set_xlabel('Epochs')
    ax1.set_ylabel('Accuracy')
    ax1.legend(['training', 'validation'])


    ax2.plot(range(1, len(loss) + 1), loss)
    ax2.plot(range(1, len(val_loss) + 1), val_loss)
    ax2.set_title('History of Loss')
    ax2.set_xlabel('Epochs')
    ax2.set_ylabel('Loss')
    ax2.legend(['training', 'validation'])
    plt.show()
    

Train_Val_Plot(fold1.history['acc'],fold1.history['val_acc'],
               fold1.history['loss'],fold1.history['val_loss'])

Train_Val_Plot(fold2.history['acc'],fold2.history['val_acc'],
               fold2.history['loss'],fold2.history['val_loss'])

Train_Val_Plot(fold3.history['acc'],fold3.history['val_acc'],
               fold3.history['loss'],fold3.history['val_loss'])

#%% LOADING THE MODEL
import keras
keras_model = keras.models.load_model('AD_Stages_model.h5')
keras_model.compile(optimizer = RMSprop(learning_rate = 1e-4),
                    loss='categorical_crossentropy', metrics =[ 'acc'])

# Prediction on test_set
pred_test = keras_model.predict(X_test, verbose=1)
# Convert the predictions to class labels
pred_test_labels = onehot.inverse_transform(pred_test)
real_val = onehot.inverse_transform(y_test)


from sklearn.metrics import roc_auc_score, auc, roc_curve, precision_recall_curve

# Generate predictions from your model
pred_test = keras_model.predict(X_test)

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 15))
fig.suptitle("ROC AND P&R VISUALIZATION")

# ROC Curve
fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(4):  # Assuming 4 classes
    # Assuming pred_test contains probabilities for each class
    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], pred_test[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])
    ax1.plot(fpr[i], tpr[i], lw=2, label='class {}'.format(i))
    ax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')

ax1.set_title("ROC Curve")
ax1.set_xlabel("False Positive Rate")
ax1.set_ylabel("True Positive Rate")
ax1.legend(loc="best")

# Precision-Recall Curve
precision = dict()
recall = dict()

for i in range(4):  # Assuming 4 classes
    # Assuming pred_test contains probabilities for each class
    precision[i], recall[i], _ = precision_recall_curve(y_test[:, i], pred_test[:, i])
    ax2.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))
    ax2.plot([1, 0], [0, 1], color='navy', lw=2, linestyle='--')

ax2.set_title("PRECISION vs. RECALL Curve")
ax2.set_xlabel("Recall")
ax2.set_ylabel("Precision")
ax2.legend(loc="best")

plt.show()

from collections import Counter
from sklearn.metrics import confusion_matrix
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Assuming you have real_val and pred_test_flat defined somewhere in your code

# Example data (replace this with your actual data)
real_val = ["class1", "class2", "class1", "class3", "class2", "class3"]
pred_test_flat = ["class1", "class2", "class1", "class2", "class2", "class3"]

# Convert string labels to numeric labels
label_mapping = {label: i for i, label in enumerate(np.unique(real_val))}
real_val_numeric = np.array([label_mapping[label] for label in real_val])

# Count occurrences of each class label
real_val_counts = Counter(real_val)
pred_test_counts = Counter(pred_test_flat)

print("Real Values:", real_val_counts)
print("Predicted Values:", pred_test_counts)

# Compute confusion matrix
conf_mx = confusion_matrix(real_val_numeric, [label_mapping[label] for label in pred_test_flat])

# Visualize confusion matrix
heat_cm = pd.DataFrame(conf_mx, columns=np.unique(real_val_numeric), index=np.unique(real_val_numeric))
heat_cm.index.name = 'Actual'
heat_cm.columns.name = 'Predicted'
plt.figure(figsize=(10, 7))
sns.set(font_scale=1.4)  # For label size
sns.heatmap(heat_cm, cmap="Blues", annot=True, annot_kws={"size": 16}, fmt='g')  # font size
plt.show()


import numpy as np
from sklearn.metrics import classification_report

# Assuming you have real_val and pred_test defined
# Example data (replace this with your actual data)
real_val = np.array([0.2, 0.7, 0.1, 0.4])
pred_test = np.array([0.1, 0.8, 0.2, 0.3])

# Convert probabilities to class labels
discrete_real_val = np.round(real_val)
discrete_pred_test = np.round(pred_test)

# Compute classification report with zero_division parameter
print(classification_report(discrete_real_val, discrete_pred_test, zero_division=1))


from tensorflow import keras
from matplotlib import pyplot
from keras.preprocessing.image import load_img
from keras.preprocessing.image import img_to_array
from numpy import expand_dims
from keras.models import Model
from skimage import color
from skimage import io


from tensorflow.compat.v1.losses import sparse_softmax_cross_entropy
import tensorflow as tf

# Example usage
labels = tf.constant([0, 1, 2])
logits = tf.constant([[0.9, 0.1, 0.1], [0.2, 0.7, 0.1], [0.1, 0.1, 0.8]])

# Calculate the loss using the updated function
loss = sparse_softmax_cross_entropy(labels=labels, logits=logits)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, Flatten, Dense

# Example of creating a simple sequential model (modify as needed)
keras_model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    Flatten(),
    Dense(10, activation='softmax')
])

# Summarizing feature map shapes
for i in range(len(keras_model.layers)):
    layer = keras_model.layers[i]
    # check for convolutional layer
    if 'conv' not in layer.name:
        continue
    # summarize output shape
    print(i, layer.name, layer.output.shape)


from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

# Example: Creating a simple convolutional neural network
keras_model = Sequential()
keras_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))
keras_model.add(MaxPooling2D((2, 2)))
keras_model.add(Conv2D(64, (3, 3), activation='relu'))
keras_model.add(MaxPooling2D((2, 2)))
keras_model.add(Conv2D(128, (3, 3), activation='relu'))
keras_model.add(MaxPooling2D((2, 2)))
keras_model.add(Flatten())
keras_model.add(Dense(128, activation='relu'))
keras_model.add(Dense(10, activation='softmax'))

# Summarizing feature map shapes
for i in range(len(keras_model.layers)):
    layer = keras_model.layers[i]
    # Check for convolutional layer
    if 'conv' in layer.name.lower():
        print(f"Layer {i}: {layer.name}, Output Shape: {layer.output_shape}")


from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
import tensorflow as tf

# Example: Creating a simple convolutional neural network
keras_model = Sequential()
keras_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))
keras_model.add(MaxPooling2D((2, 2)))
keras_model.add(Conv2D(64, (3, 3), activation='relu'))
keras_model.add(MaxPooling2D((2, 2)))
keras_model.add(Conv2D(128, (3, 3), activation='relu'))
keras_model.add(MaxPooling2D((2, 2)))
keras_model.add(Flatten())
keras_model.add(Dense(128, activation='relu'))
keras_model.add(Dense(10, activation='softmax'))

# Summarizing feature map shapes
for i in range(len(keras_model.layers)):
    layer = keras_model.layers[i]
    # Check for convolutional layer
    if 'conv' in layer.name.lower():
        print(f"Layer {i}: {layer.name}, Output Shape: {layer.output_shape}")


from skimage import io
from numpy import expand_dims

# Corrected file path and read image
img_path = r'C:\\Users\\hp\\OneDrive\\Desktop\\MCA FINAL\\Alzheimer_s Dataset\\train\\ModerateDemented\\moderateDem0.jpg'
img = io.imread(img_path)

# Add a batch dimension
img_expanded = expand_dims(img, axis=0)

pip install scikit-image numpy

from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.vgg16 import preprocess_input

# Load and preprocess the image
img_path = r'C:\\Users\\hp\\OneDrive\\Desktop\\MCA FINAL\\Alzheimer_s Dataset\\train\\ModerateDemented\\moderateDem0.jpg'
img = image.load_img(img_path, target_size=(64, 64))
img_array = image.img_to_array(img)
img_array = preprocess_input(img_array)
img_expanded = expand_dims(img_array, axis=0)

# Visualize feature maps
feature_maps = model3.predict(img_expanded)

# Set the number of feature maps to display in each row and column
square = 2

for fmap in feature_maps:
    # Plot all feature maps in an 8x8 grid
    ix = 1
    for _ in range(square):
        for _ in range(square):
            # Specify subplot and turn off axis
            ax = plt.subplot(square, 2, ix)
            ax.set_xticks([])
            ax.set_yticks([])
            # Plot filter channel in grayscale
            plt.imshow(fmap[0, :, :, ix - 1], cmap='gray')
            ix += 1
    # Show the figure
    plt.show()


